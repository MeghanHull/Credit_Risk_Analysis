{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RICE-VIRT-DATA-PT-05-2022-U-B-MW Module 17 Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Summary\n",
    "- **Purpose  :** Evaluation of Credit Risk Machine Learning Resampling Algorithms \n",
    "- **Created  :** 2022 Sept 07 22:25:12 UTC (Meghan E. Hull)\n",
    "- **Modified :** 2022 Sept 08 02:23:12 UTC (Meghan E. Hull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy                     1.21.5           py37h7a0a035_1  \n",
      "numpy-base                1.21.5           py37hca35cd5_1  \n",
      "numpydoc                  1.2                pyhd3eb1b0_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list | findstr numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas                    1.3.5            py37h6214cd6_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list | findstr pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy                     1.7.3            py37h0a974cb_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list | findstr scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn              1.0.2            py37hf11a4ad_1  \n",
      "scikit-learn-intelex      2021.5.0         py37haa95532_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list | findstr scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imbalanced-learn          0.9.0                    pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "!conda list | findstr imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institate a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(columns=['Balanced Accuracy Score', \n",
    "                                   'High Risk Precision Score', \n",
    "                                   'Low Risk Precision Score', \n",
    "                                   'High Risk Recall Score', \n",
    "                                   'Low Risk Recall Score',\n",
    "                                   'High Risk F1 Score', \n",
    "                                   'Low Risk F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import & Prep Client Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import & Initial Cleaning of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('Data/LoanStats_2019Q1.csv')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File name\n",
    "file_path = Path('Data/LoanStats_2019Q1.csv')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in .csv file\n",
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n",
    "    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n",
    "    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n",
    "    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n",
    "    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n",
    "    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n",
    "    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n",
    "    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n",
    "    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n",
    "    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n",
    "    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n",
    "    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n",
    "    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n",
    "]\n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10500.0</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>375.35</td>\n",
       "      <td>RENT</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>27.24</td>\n",
       "      <td>...</td>\n",
       "      <td>85.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65687.0</td>\n",
       "      <td>38199.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>61987.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>929.09</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>20.23</td>\n",
       "      <td>...</td>\n",
       "      <td>91.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271427.0</td>\n",
       "      <td>60641.0</td>\n",
       "      <td>41200.0</td>\n",
       "      <td>49197.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>529.88</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>24.26</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60644.0</td>\n",
       "      <td>45684.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>43144.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>353.55</td>\n",
       "      <td>RENT</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>31.44</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99506.0</td>\n",
       "      <td>68784.0</td>\n",
       "      <td>19700.0</td>\n",
       "      <td>76506.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22000.0</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>520.39</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Mar-2019</td>\n",
       "      <td>low_risk</td>\n",
       "      <td>n</td>\n",
       "      <td>18.76</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219750.0</td>\n",
       "      <td>25919.0</td>\n",
       "      <td>27600.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0    10500.0    0.1719       375.35           RENT     66000.0   \n",
       "1    25000.0    0.2000       929.09       MORTGAGE    105000.0   \n",
       "2    20000.0    0.2000       529.88       MORTGAGE     56000.0   \n",
       "3    10000.0    0.1640       353.55           RENT     92000.0   \n",
       "4    22000.0    0.1474       520.39       MORTGAGE     52000.0   \n",
       "\n",
       "  verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n",
       "0     Source Verified  Mar-2019    low_risk          n  27.24  ...   \n",
       "1            Verified  Mar-2019    low_risk          n  20.23  ...   \n",
       "2            Verified  Mar-2019    low_risk          n  24.26  ...   \n",
       "3            Verified  Mar-2019    low_risk          n  31.44  ...   \n",
       "4        Not Verified  Mar-2019    low_risk          n  18.76  ...   \n",
       "\n",
       "   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "0            85.7             100.0                   0.0        0.0   \n",
       "1            91.2              50.0                   1.0        0.0   \n",
       "2            66.7              50.0                   0.0        0.0   \n",
       "3           100.0              50.0                   1.0        0.0   \n",
       "4           100.0               0.0                   0.0        0.0   \n",
       "\n",
       "   tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n",
       "0          65687.0            38199.0         2000.0   \n",
       "1         271427.0            60641.0        41200.0   \n",
       "2          60644.0            45684.0         7500.0   \n",
       "3          99506.0            68784.0        19700.0   \n",
       "4         219750.0            25919.0        27600.0   \n",
       "\n",
       "   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n",
       "0                     61987.0              N                     N  \n",
       "1                     49197.0              N                     N  \n",
       "2                     43144.0              N                     N  \n",
       "3                     76506.0              N                     N  \n",
       "4                     20000.0              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                     float64\n",
      "int_rate                      float64\n",
      "installment                   float64\n",
      "home_ownership                 object\n",
      "annual_inc                    float64\n",
      "verification_status            object\n",
      "issue_d                        object\n",
      "loan_status                    object\n",
      "pymnt_plan                     object\n",
      "dti                           float64\n",
      "delinq_2yrs                   float64\n",
      "inq_last_6mths                float64\n",
      "open_acc                      float64\n",
      "pub_rec                       float64\n",
      "revol_bal                     float64\n",
      "total_acc                     float64\n",
      "initial_list_status            object\n",
      "out_prncp                     float64\n",
      "out_prncp_inv                 float64\n",
      "total_pymnt                   float64\n",
      "total_pymnt_inv               float64\n",
      "total_rec_prncp               float64\n",
      "total_rec_int                 float64\n",
      "total_rec_late_fee            float64\n",
      "recoveries                    float64\n",
      "collection_recovery_fee       float64\n",
      "last_pymnt_amnt               float64\n",
      "next_pymnt_d                   object\n",
      "collections_12_mths_ex_med    float64\n",
      "policy_code                   float64\n",
      "application_type               object\n",
      "acc_now_delinq                float64\n",
      "tot_coll_amt                  float64\n",
      "tot_cur_bal                   float64\n",
      "open_acc_6m                   float64\n",
      "open_act_il                   float64\n",
      "open_il_12m                   float64\n",
      "open_il_24m                   float64\n",
      "mths_since_rcnt_il            float64\n",
      "total_bal_il                  float64\n",
      "il_util                       float64\n",
      "open_rv_12m                   float64\n",
      "open_rv_24m                   float64\n",
      "max_bal_bc                    float64\n",
      "all_util                      float64\n",
      "total_rev_hi_lim              float64\n",
      "inq_fi                        float64\n",
      "total_cu_tl                   float64\n",
      "inq_last_12m                  float64\n",
      "acc_open_past_24mths          float64\n",
      "avg_cur_bal                   float64\n",
      "bc_open_to_buy                float64\n",
      "bc_util                       float64\n",
      "chargeoff_within_12_mths      float64\n",
      "delinq_amnt                   float64\n",
      "mo_sin_old_il_acct            float64\n",
      "mo_sin_old_rev_tl_op          float64\n",
      "mo_sin_rcnt_rev_tl_op         float64\n",
      "mo_sin_rcnt_tl                float64\n",
      "mort_acc                      float64\n",
      "mths_since_recent_bc          float64\n",
      "mths_since_recent_inq         float64\n",
      "num_accts_ever_120_pd         float64\n",
      "num_actv_bc_tl                float64\n",
      "num_actv_rev_tl               float64\n",
      "num_bc_sats                   float64\n",
      "num_bc_tl                     float64\n",
      "num_il_tl                     float64\n",
      "num_op_rev_tl                 float64\n",
      "num_rev_accts                 float64\n",
      "num_rev_tl_bal_gt_0           float64\n",
      "num_sats                      float64\n",
      "num_tl_120dpd_2m              float64\n",
      "num_tl_30dpd                  float64\n",
      "num_tl_90g_dpd_24m            float64\n",
      "num_tl_op_past_12m            float64\n",
      "pct_tl_nvr_dlq                float64\n",
      "percent_bc_gt_75              float64\n",
      "pub_rec_bankruptcies          float64\n",
      "tax_liens                     float64\n",
      "tot_hi_cred_lim               float64\n",
      "total_bal_ex_mort             float64\n",
      "total_bc_limit                float64\n",
      "total_il_high_credit_limit    float64\n",
      "hardship_flag                  object\n",
      "debt_settlement_flag           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check column types\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split into Training & Testing\n",
    "The data has been split along the following parameters:\n",
    "- Target values are in the column \"loan_status\"\n",
    "- Features values are converted from strings to numbers using the `get_dummies()` method, excluding the columns:\n",
    "  - Text columns - \"home_ownership\", \"verification_status\", \"initial_list_status\", \"application_type\"\n",
    "  - Date columns - \"issue_d\", \"next_pymnt_d\"\n",
    "  - Boolean / \"Y/N\" columns - \"pymnt_plan\", \"hardship_flag\", \"debt_settlement_flag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target\n",
    "y = pd.DataFrame(df[\"loan_status\"])\n",
    "\n",
    "# Create features\n",
    "X = pd.get_dummies(df, columns=['home_ownership', \n",
    "                                'verification_status', \n",
    "                                'issue_d', \n",
    "                                'pymnt_plan',\n",
    "                                'initial_list_status', \n",
    "                                'next_pymnt_d', \n",
    "                                'application_type', \n",
    "                                'hardship_flag', \n",
    "                                'debt_settlement_flag']).drop('loan_status', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_d_Mar-2019</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>next_pymnt_d_Apr-2019</th>\n",
       "      <th>next_pymnt_d_May-2019</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>6.881700e+04</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.0</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.0</td>\n",
       "      <td>68817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16677.594562</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>480.652863</td>\n",
       "      <td>8.821371e+04</td>\n",
       "      <td>21.778153</td>\n",
       "      <td>0.217766</td>\n",
       "      <td>0.497697</td>\n",
       "      <td>12.587340</td>\n",
       "      <td>0.126030</td>\n",
       "      <td>17604.142828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.876121</td>\n",
       "      <td>0.383161</td>\n",
       "      <td>0.616839</td>\n",
       "      <td>0.860340</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10277.348590</td>\n",
       "      <td>0.048130</td>\n",
       "      <td>288.062432</td>\n",
       "      <td>1.155800e+05</td>\n",
       "      <td>20.199244</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.758122</td>\n",
       "      <td>6.022869</td>\n",
       "      <td>0.336797</td>\n",
       "      <td>21835.880400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>30.890000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9000.000000</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>265.730000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>13.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6293.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>404.560000</td>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12068.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>648.100000</td>\n",
       "      <td>1.040000e+05</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21735.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>1676.230000</td>\n",
       "      <td>8.797500e+06</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>587191.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt      int_rate   installment    annual_inc           dti  \\\n",
       "count  68817.000000  68817.000000  68817.000000  6.881700e+04  68817.000000   \n",
       "mean   16677.594562      0.127718    480.652863  8.821371e+04     21.778153   \n",
       "std    10277.348590      0.048130    288.062432  1.155800e+05     20.199244   \n",
       "min     1000.000000      0.060000     30.890000  4.000000e+01      0.000000   \n",
       "25%     9000.000000      0.088100    265.730000  5.000000e+04     13.890000   \n",
       "50%    15000.000000      0.118000    404.560000  7.300000e+04     19.760000   \n",
       "75%    24000.000000      0.155700    648.100000  1.040000e+05     26.660000   \n",
       "max    40000.000000      0.308400   1676.230000  8.797500e+06    999.000000   \n",
       "\n",
       "        delinq_2yrs  inq_last_6mths      open_acc       pub_rec  \\\n",
       "count  68817.000000    68817.000000  68817.000000  68817.000000   \n",
       "mean       0.217766        0.497697     12.587340      0.126030   \n",
       "std        0.718367        0.758122      6.022869      0.336797   \n",
       "min        0.000000        0.000000      2.000000      0.000000   \n",
       "25%        0.000000        0.000000      8.000000      0.000000   \n",
       "50%        0.000000        0.000000     11.000000      0.000000   \n",
       "75%        0.000000        1.000000     16.000000      0.000000   \n",
       "max       18.000000        5.000000     72.000000      4.000000   \n",
       "\n",
       "           revol_bal  ...  issue_d_Mar-2019  pymnt_plan_n  \\\n",
       "count   68817.000000  ...      68817.000000       68817.0   \n",
       "mean    17604.142828  ...          0.177238           1.0   \n",
       "std     21835.880400  ...          0.381873           0.0   \n",
       "min         0.000000  ...          0.000000           1.0   \n",
       "25%      6293.000000  ...          0.000000           1.0   \n",
       "50%     12068.000000  ...          0.000000           1.0   \n",
       "75%     21735.000000  ...          0.000000           1.0   \n",
       "max    587191.000000  ...          1.000000           1.0   \n",
       "\n",
       "       initial_list_status_f  initial_list_status_w  next_pymnt_d_Apr-2019  \\\n",
       "count           68817.000000           68817.000000           68817.000000   \n",
       "mean                0.123879               0.876121               0.383161   \n",
       "std                 0.329446               0.329446               0.486161   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               1.000000               0.000000   \n",
       "50%                 0.000000               1.000000               0.000000   \n",
       "75%                 0.000000               1.000000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       next_pymnt_d_May-2019  application_type_Individual  \\\n",
       "count           68817.000000                 68817.000000   \n",
       "mean                0.616839                     0.860340   \n",
       "std                 0.486161                     0.346637   \n",
       "min                 0.000000                     0.000000   \n",
       "25%                 0.000000                     1.000000   \n",
       "50%                 1.000000                     1.000000   \n",
       "75%                 1.000000                     1.000000   \n",
       "max                 1.000000                     1.000000   \n",
       "\n",
       "       application_type_Joint App  hardship_flag_N  debt_settlement_flag_N  \n",
       "count                68817.000000          68817.0                 68817.0  \n",
       "mean                     0.139660              1.0                     1.0  \n",
       "std                      0.346637              0.0                     0.0  \n",
       "min                      0.000000              1.0                     1.0  \n",
       "25%                      0.000000              1.0                     1.0  \n",
       "50%                      0.000000              1.0                     1.0  \n",
       "75%                      0.000000              1.0                     1.0  \n",
       "max                      1.000000              1.0                     1.0  \n",
       "\n",
       "[8 rows x 95 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>low_risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loan_status\n",
       "0    low_risk\n",
       "1    low_risk\n",
       "2    low_risk\n",
       "3    low_risk\n",
       "4    low_risk\n",
       "5    low_risk\n",
       "6    low_risk\n",
       "7    low_risk\n",
       "8    low_risk\n",
       "9    low_risk"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low_risk     68470\n",
       "high_risk      347\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of target values\n",
    "y['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature (X) Data Sets\n",
      "X_train Shape: (51612, 95)\n",
      "X_test Shape: (17205, 95)\n",
      "\n",
      "Target (y) Data Sets\n",
      "y_train Shape: (51612, 1)\n",
      "y_test Shape: (17205, 1)\n",
      "\n",
      "Target (y) Counters\n",
      "y_train: Counter({'loan_status': 1})\n",
      "y_test: Counter({'loan_status': 1})\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "print('Feature (X) Data Sets')\n",
    "print(f'X_train Shape: {X_train.shape}')\n",
    "print(f'X_test Shape: {X_test.shape}')\n",
    "print('')\n",
    "print('Target (y) Data Sets')\n",
    "print(f'y_train Shape: {y_train.shape}')\n",
    "print(f'y_test Shape: {y_test.shape}')\n",
    "print('')\n",
    "print('Target (y) Counters')\n",
    "print(f'y_train: {Counter(y_train)}')\n",
    "print(f'y_test: {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Oversampling\n",
    "## 2.1 Overview\n",
    "In this section, two oversampling algorithms are compared to determine which algorithm results in the best performance: the naive random oversampling algorithm and the SMOTE algorithm. Each algorithm uses the folliowing steps:\n",
    "\n",
    "1. Resample data with algorithm & view the count of the target classes using `Counter` from the collections library. \n",
    "3. Train a logistic regression model with the resampled data.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "**Note:** A random state of 1 is used for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Naive Random Oversampling (`RandomOverSampler`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Resample training data with algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'loan_status': 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the model\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Resample the targets\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Train model & predict test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted target values\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Balanced Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285327805778149"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "modelBAScore = balanced_accuracy_score(y_test, y_pred)\n",
    "modelBAScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>5831</td>\n",
       "      <td>11287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                   52                  35\n",
       "Actual low_risk                  5831               11287"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "myCM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "myCM_df = pd.DataFrame(\n",
    "    myCM, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "myCM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.01      0.60      0.66      0.02      0.63      0.39        87\n",
      "   low_risk       1.00      0.66      0.60      0.79      0.63      0.40     17118\n",
      "\n",
      "avg / total       0.99      0.66      0.60      0.79      0.63      0.40     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "myReport = classification_report_imbalanced(y_test, y_pred, output_dict=True)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>High Risk Precision Score</th>\n",
       "      <th>Low Risk Precision Score</th>\n",
       "      <th>High Risk Recall Score</th>\n",
       "      <th>Low Risk Recall Score</th>\n",
       "      <th>High Risk F1 Score</th>\n",
       "      <th>Low Risk F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Random Oversampling</th>\n",
       "      <td>0.628533</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.659364</td>\n",
       "      <td>0.01742</td>\n",
       "      <td>0.793741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Balanced Accuracy Score  High Risk Precision Score  \\\n",
       "Naive Random Oversampling                 0.628533                   0.008839   \n",
       "\n",
       "                           Low Risk Precision Score  High Risk Recall Score  \\\n",
       "Naive Random Oversampling                  0.996909                0.597701   \n",
       "\n",
       "                           Low Risk Recall Score  High Risk F1 Score  \\\n",
       "Naive Random Oversampling               0.659364             0.01742   \n",
       "\n",
       "                           Low Risk F1 Score  \n",
       "Naive Random Oversampling           0.793741  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.loc['Naive Random Oversampling'] = [modelBAScore,\n",
    "                                               myReport['high_risk']['pre'],\n",
    "                                               myReport['low_risk']['pre'],\n",
    "                                               myReport['high_risk']['rec'],\n",
    "                                               myReport['low_risk']['rec'],\n",
    "                                               myReport['high_risk']['f1'],\n",
    "                                               myReport['low_risk']['f1']]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Resample training data with algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'loan_status': 1})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Instantiate the model\n",
    "mySMOTE = SMOTE(random_state=1)\n",
    "\n",
    "# Resample the targets\n",
    "X_resampled, y_resampled = mySMOTE.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Train model & predict test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted target values\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Balanced Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417211565966053"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "modelBAScore = balanced_accuracy_score(y_test, y_pred)\n",
    "modelBAScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>5773</td>\n",
       "      <td>11345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                   54                  33\n",
       "Actual low_risk                  5773               11345"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "myCM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "myCM_df = pd.DataFrame(\n",
    "    myCM, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "myCM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.01      0.62      0.66      0.02      0.64      0.41        87\n",
      "   low_risk       1.00      0.66      0.62      0.80      0.64      0.41     17118\n",
      "\n",
      "avg / total       0.99      0.66      0.62      0.79      0.64      0.41     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "myReport = classification_report_imbalanced(y_test, y_pred, output_dict=True)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>High Risk Precision Score</th>\n",
       "      <th>Low Risk Precision Score</th>\n",
       "      <th>High Risk Recall Score</th>\n",
       "      <th>Low Risk Recall Score</th>\n",
       "      <th>High Risk F1 Score</th>\n",
       "      <th>Low Risk F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Random Oversampling</th>\n",
       "      <td>0.628533</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.659364</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.793741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <td>0.641721</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.018262</td>\n",
       "      <td>0.796252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Balanced Accuracy Score  High Risk Precision Score  \\\n",
       "Naive Random Oversampling                 0.628533                   0.008839   \n",
       "SMOTE Oversampling                        0.641721                   0.009267   \n",
       "\n",
       "                           Low Risk Precision Score  High Risk Recall Score  \\\n",
       "Naive Random Oversampling                  0.996909                0.597701   \n",
       "SMOTE Oversampling                         0.997100                0.620690   \n",
       "\n",
       "                           Low Risk Recall Score  High Risk F1 Score  \\\n",
       "Naive Random Oversampling               0.659364            0.017420   \n",
       "SMOTE Oversampling                      0.662753            0.018262   \n",
       "\n",
       "                           Low Risk F1 Score  \n",
       "Naive Random Oversampling           0.793741  \n",
       "SMOTE Oversampling                  0.796252  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.loc['SMOTE Oversampling'] = [modelBAScore,\n",
    "                                               myReport['high_risk']['pre'],\n",
    "                                               myReport['low_risk']['pre'],\n",
    "                                               myReport['high_risk']['rec'],\n",
    "                                               myReport['low_risk']['rec'],\n",
    "                                               myReport['high_risk']['f1'],\n",
    "                                               myReport['low_risk']['f1']]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Undersampling\n",
    "\n",
    "## 3.1 Overview\n",
    "In this section, the undersampling algorithm Cluster Centroids is utilized. The same steps are used as for oversampling:\n",
    "\n",
    "1. Resample data with algorithm & view the count of the target classes using `Counter` from the collections library. \n",
    "3. Train a logistic regression model with the resampled data.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "**Note:** A random state of 1 is used for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cluster Centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Resample training data with algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'loan_status': 1})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "# Instantiate the model\n",
    "myCC = ClusterCentroids(random_state=1)\n",
    "\n",
    "# Resample the targets\n",
    "X_resampled, y_resampled = myCC.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Train model & predict test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted target values\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Balanced Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5300701822239949"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "modelBAScore = balanced_accuracy_score(y_test, y_pred)\n",
    "modelBAScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>9989</td>\n",
       "      <td>7129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                   56                  31\n",
       "Actual low_risk                  9989                7129"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "myCM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "myCM_df = pd.DataFrame(\n",
    "    myCM, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "myCM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.01      0.64      0.42      0.01      0.52      0.27        87\n",
      "   low_risk       1.00      0.42      0.64      0.59      0.52      0.26     17118\n",
      "\n",
      "avg / total       0.99      0.42      0.64      0.58      0.52      0.26     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "myReport = classification_report_imbalanced(y_test, y_pred, output_dict=True)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>High Risk Precision Score</th>\n",
       "      <th>Low Risk Precision Score</th>\n",
       "      <th>High Risk Recall Score</th>\n",
       "      <th>Low Risk Recall Score</th>\n",
       "      <th>High Risk F1 Score</th>\n",
       "      <th>Low Risk F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Random Oversampling</th>\n",
       "      <td>0.628533</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.659364</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.793741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <td>0.641721</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.018262</td>\n",
       "      <td>0.796252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster Centroids Undersampling</th>\n",
       "      <td>0.530070</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.995670</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.416462</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.587281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Balanced Accuracy Score  \\\n",
       "Naive Random Oversampling                       0.628533   \n",
       "SMOTE Oversampling                              0.641721   \n",
       "Cluster Centroids Undersampling                 0.530070   \n",
       "\n",
       "                                 High Risk Precision Score  \\\n",
       "Naive Random Oversampling                         0.008839   \n",
       "SMOTE Oversampling                                0.009267   \n",
       "Cluster Centroids Undersampling                   0.005575   \n",
       "\n",
       "                                 Low Risk Precision Score  \\\n",
       "Naive Random Oversampling                        0.996909   \n",
       "SMOTE Oversampling                               0.997100   \n",
       "Cluster Centroids Undersampling                  0.995670   \n",
       "\n",
       "                                 High Risk Recall Score  \\\n",
       "Naive Random Oversampling                      0.597701   \n",
       "SMOTE Oversampling                             0.620690   \n",
       "Cluster Centroids Undersampling                0.643678   \n",
       "\n",
       "                                 Low Risk Recall Score  High Risk F1 Score  \\\n",
       "Naive Random Oversampling                     0.659364            0.017420   \n",
       "SMOTE Oversampling                            0.662753            0.018262   \n",
       "Cluster Centroids Undersampling               0.416462            0.011054   \n",
       "\n",
       "                                 Low Risk F1 Score  \n",
       "Naive Random Oversampling                 0.793741  \n",
       "SMOTE Oversampling                        0.796252  \n",
       "Cluster Centroids Undersampling           0.587281  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.loc['Cluster Centroids Undersampling'] = [modelBAScore,\n",
    "                                               myReport['high_risk']['pre'],\n",
    "                                               myReport['low_risk']['pre'],\n",
    "                                               myReport['high_risk']['rec'],\n",
    "                                               myReport['low_risk']['rec'],\n",
    "                                               myReport['high_risk']['f1'],\n",
    "                                               myReport['low_risk']['f1']]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Combination (Over and Under) Sampling\n",
    "## 4.1 Overview\n",
    "In this section, a combination over- and under-sampling algorithm SMOTEENN is utilized. The same steps are used as for oversampling:\n",
    "\n",
    "1. Resample data with algorithm & view the count of the target classes using `Counter` from the collections library. \n",
    "3. Train a logistic regression model with the resampled data.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "**Note:** A random state of 1 is used for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Resample training data with algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'loan_status': 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Instantiate the model\n",
    "mySMOTEENN = SMOTEENN(random_state=1)\n",
    "\n",
    "# Resample the targets\n",
    "X_resampled, y_resampled = mySMOTEENN.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Train model & predict test target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "classifier.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted target values\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Balanced Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651763016143523"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "modelBAScore = balanced_accuracy_score(y_test, y_pred)\n",
    "modelBAScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted high_risk</th>\n",
       "      <th>Predicted low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual high_risk</th>\n",
       "      <td>59</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual low_risk</th>\n",
       "      <td>6413</td>\n",
       "      <td>10705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted high_risk  Predicted low_risk\n",
       "Actual high_risk                   59                  28\n",
       "Actual low_risk                  6413               10705"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "myCM = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "myCM_df = pd.DataFrame(\n",
    "    myCM, index=[\"Actual high_risk\", \"Actual low_risk\"], columns=[\"Predicted high_risk\", \"Predicted low_risk\"])\n",
    "myCM_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.01      0.68      0.63      0.02      0.65      0.43        87\n",
      "   low_risk       1.00      0.63      0.68      0.77      0.65      0.42     17118\n",
      "\n",
      "avg / total       0.99      0.63      0.68      0.76      0.65      0.42     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "myReport = classification_report_imbalanced(y_test, y_pred, output_dict=True)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy Score</th>\n",
       "      <th>High Risk Precision Score</th>\n",
       "      <th>Low Risk Precision Score</th>\n",
       "      <th>High Risk Recall Score</th>\n",
       "      <th>Low Risk Recall Score</th>\n",
       "      <th>High Risk F1 Score</th>\n",
       "      <th>Low Risk F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Random Oversampling</th>\n",
       "      <td>0.628533</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.659364</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.793741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <td>0.641721</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.018262</td>\n",
       "      <td>0.796252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster Centroids Undersampling</th>\n",
       "      <td>0.530070</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.995670</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.416462</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.587281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN Hybrid Sampling</th>\n",
       "      <td>0.651763</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.625365</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>0.768734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Balanced Accuracy Score  \\\n",
       "Naive Random Oversampling                       0.628533   \n",
       "SMOTE Oversampling                              0.641721   \n",
       "Cluster Centroids Undersampling                 0.530070   \n",
       "SMOTEENN Hybrid Sampling                        0.651763   \n",
       "\n",
       "                                 High Risk Precision Score  \\\n",
       "Naive Random Oversampling                         0.008839   \n",
       "SMOTE Oversampling                                0.009267   \n",
       "Cluster Centroids Undersampling                   0.005575   \n",
       "SMOTEENN Hybrid Sampling                          0.009116   \n",
       "\n",
       "                                 Low Risk Precision Score  \\\n",
       "Naive Random Oversampling                        0.996909   \n",
       "SMOTE Oversampling                               0.997100   \n",
       "Cluster Centroids Undersampling                  0.995670   \n",
       "SMOTEENN Hybrid Sampling                         0.997391   \n",
       "\n",
       "                                 High Risk Recall Score  \\\n",
       "Naive Random Oversampling                      0.597701   \n",
       "SMOTE Oversampling                             0.620690   \n",
       "Cluster Centroids Undersampling                0.643678   \n",
       "SMOTEENN Hybrid Sampling                       0.678161   \n",
       "\n",
       "                                 Low Risk Recall Score  High Risk F1 Score  \\\n",
       "Naive Random Oversampling                     0.659364            0.017420   \n",
       "SMOTE Oversampling                            0.662753            0.018262   \n",
       "Cluster Centroids Undersampling               0.416462            0.011054   \n",
       "SMOTEENN Hybrid Sampling                      0.625365            0.017991   \n",
       "\n",
       "                                 Low Risk F1 Score  \n",
       "Naive Random Oversampling                 0.793741  \n",
       "SMOTE Oversampling                        0.796252  \n",
       "Cluster Centroids Undersampling           0.587281  \n",
       "SMOTEENN Hybrid Sampling                  0.768734  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.loc['SMOTEENN Hybrid Sampling'] = [modelBAScore,\n",
    "                                               myReport['high_risk']['pre'],\n",
    "                                               myReport['low_risk']['pre'],\n",
    "                                               myReport['high_risk']['rec'],\n",
    "                                               myReport['low_risk']['rec'],\n",
    "                                               myReport['high_risk']['f1'],\n",
    "                                               myReport['low_risk']['f1']]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path('Data/Resampling_Summary.csv')\n",
    "summary_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
